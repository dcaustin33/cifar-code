{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fb71608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "import torch\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "from flax.training import train_state \n",
    "\n",
    "from utils import get_accuracy\n",
    "from lars import LARSWrapper\n",
    "import cifar_100\n",
    "from logger import log_metrics as logger\n",
    "import torch_trainer as trainer\n",
    "from cifar_resnet import resnet18\n",
    "import cifar_100\n",
    "\n",
    "#python helper inputs\n",
    "import os\n",
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "dataset_args = {\n",
    "                 'crop_size': 32,\n",
    "                 'brightness': 0.4, \n",
    "                 'contrast': 0.4, \n",
    "                 'saturation': .2, \n",
    "                 'hue': .1, \n",
    "                 'color_jitter_prob': .8, \n",
    "                 'gray_scale_prob': 0.2, \n",
    "                 'horizontal_flip_prob': 0.5, \n",
    "                 'gaussian_prob': .5, \n",
    "                 'min_scale': 0.16, \n",
    "                 'max_scale': 0.9}\n",
    "val_dataset_args = {\n",
    "                 'crop_size': 32,\n",
    "                 'brightness': 0.4, \n",
    "                 'contrast': 0.4, \n",
    "                 'saturation': .2, \n",
    "                 'hue': .1, \n",
    "                 'color_jitter_prob': 0, \n",
    "                 'gray_scale_prob': 0, \n",
    "                 'horizontal_flip_prob': 0.5, \n",
    "                 'gaussian_prob': 0, \n",
    "                 'min_scale': 0.9, \n",
    "                 'max_scale': 1}\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data(dataset_args, val_dataset_args):\n",
    "    \n",
    "    train_dataset = cifar_100.CIFAR_100_transformations(train = True, **dataset_args)\n",
    "    dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        shuffle = True,\n",
    "        batch_size=2,\n",
    "        num_workers=2,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    val_dataset = cifar_100.CIFAR_100_transformations(train = True, **val_dataset_args)\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        shuffle = True,\n",
    "        batch_size=2,\n",
    "        num_workers=2,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        persistent_workers=False\n",
    "    )\n",
    "    return train_dataset, dataloader, val_dataloader\n",
    "\n",
    "\n",
    "def cross_entropy_loss(logits, labels):\n",
    "    labels_onehot = jax.nn.one_hot(labels, num_classes=100)\n",
    "    return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()\n",
    "\n",
    "def compute_metrics(logits, labels):\n",
    "    loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "def create_train_state(rng, learning_rate, momentum):\n",
    "    \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "    model = resnet18()\n",
    "    batch = jnp.ones((4, 32, 32, 3))  # (N, H, W, C) format\n",
    "    params = model.init(jax.random.PRNGKey(0), batch)['params']\n",
    "    tx = optax.sgd(learning_rate, momentum)\n",
    "    return train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "\n",
    "    def loss_fn(params):\n",
    "        logits, _ = resnet18().apply({'params': params}, batch['image0'], mutable=['batch_stats'])\n",
    "        loss = cross_entropy_loss(logits=logits, labels=batch['label'])\n",
    "        return loss, logits\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, logits), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = compute_metrics(logits=logits, labels=batch['label'])\n",
    "    \n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afcb4358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flax.training.train_state.TrainState"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f3c46e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "state = create_train_state(init_rng, learning_rate, momentum)\n",
    "del init_rng  # Must not be used anymore.\n",
    "\n",
    "\n",
    "\n",
    "for i, data in enumerate(dataloader):\n",
    "    data['image0'] = jnp.array(data['image0'].permute(0, 2, 3, 1))\n",
    "    data['label'] = jnp.array(data['label'])\n",
    "    state, metrics = train_step(state, data)\n",
    "    #logits = resnet18().apply({'params': state.params}, data['image0'], mutable=['batch_stats'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08b4854b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mout\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494288cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset, dataloader, val_dataloader = prepare_data(dataset_args, val_dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe9c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
